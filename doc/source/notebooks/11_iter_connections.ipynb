{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating over connections with `iter_connections`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "The code in this section assumes that you have already downloaded the circuit. If not, take a look at the [first notebook](./01_node_properties.ipynb) in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bluepysnap\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "circuit_path = \"sonata/circuit_sonata.json\"\n",
    "circuit = bluepysnap.Circuit(circuit_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "As mentioned before, due to the huge number of edges, we may run into memory issues. Therefore, it's highly recommended to use iterators instead of gathering all of the data at once. For this very reason, SNAP has `iter_connections`:\n",
    "```python\n",
    "edge_population.iter_connections(\n",
    "    source,                   # the source nodes / query\n",
    "    target,                   # the target nodes / query\n",
    "    unique_node_ids=False,    # only use each source/target id once\n",
    "    shuffle=False,            # shuffle the order of results\n",
    "    return_edge_ids=False,    # return also the edge ids\n",
    "    return_edge_count=False,  # return the edge count between the source-target pairs\n",
    ")\n",
    "# Returns a generator of tuples containing:\n",
    "# (source_id, target_id)             : normally\n",
    "# (source_id, target_id, edge_ids)   : if return_edge_ids=True\n",
    "# (source_id, target_id, edge_count) : if return_edge_count=True\n",
    "```\n",
    "**NOTE:** `return_edge_ids` and `return_edge_count` are mutually exclusive options.\n",
    "\n",
    "In a nutshell, what `iter_connections` does, is that it iterates through **all** of the existing connections (source-target pairs) from **any** of the **source nodes** to **any** of the **target nodes** and returns a generator yielding those source-target pairs.\n",
    "\n",
    "Let's look at a few examples.\n",
    "\n",
    "## Return value is a generator that we can iterate over\n",
    "This is just to empahasize that we don't get the results of the function until we actually loop over it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is not a tuple or a list but a <class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "source_ids = [1]\n",
    "target_ids = [27204]\n",
    "edge_population = circuit.edges['thalamus_neurons__thalamus_neurons__chemical']\n",
    "\n",
    "it = edge_population.iter_connections(source_ids, target_ids)\n",
    "print(f\"The result is not a tuple or a list but a {type(it)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we could convert the result to a list using `list(it)` or `[*it]` but that kind of defeats the purpose of using generators and iterators. We'll just loop through them in the examples to not reinforce \"bad habits\".\n",
    "\n",
    "## No optional flags set\n",
    "This example is just to demonstrate that without `return_edge_ids`/`return_edge_count`, we're merely getting the source and target nodes ids as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CircuitNodeId(population='thalamus_neurons', id=1) - CircuitNodeId(population='thalamus_neurons', id=27204)\n"
     ]
    }
   ],
   "source": [
    "for _source_id, _target_id in edge_population.iter_connections(source_ids, target_ids):\n",
    "    print(_source_id, '-', _target_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning edge ids\n",
    "\n",
    "By setting `return_edge_ids=True`, we get the ids of the edges connecting each source-target pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CircuitNodeId(population='thalamus_neurons', id=1) - CircuitNodeId(population='thalamus_neurons', id=27204)\n",
      "\n",
      "CircuitEdgeIds([('thalamus_neurons__thalamus_neurons__chemical', 11570852),\n",
      "            ('thalamus_neurons__thalamus_neurons__chemical', 11570853),\n",
      "            ('thalamus_neurons__thalamus_neurons__chemical', 11570854),\n",
      "            ('thalamus_neurons__thalamus_neurons__chemical', 11570855)],\n",
      "           names=['population', 'edge_ids'])\n"
     ]
    }
   ],
   "source": [
    "for _source_id, _target_id, _edge_ids in edge_population.iter_connections(source_ids, target_ids, return_edge_ids=True):\n",
    "    print(_source_id, '-', _target_id)\n",
    "    print(f'\\n{_edge_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning the number of connecting edges\n",
    "\n",
    "By setting `return_edge_count=True`, we get the number of edges connecting each source-target pair. Based on the previous example, we should be getting four connecting edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CircuitNodeId(population='thalamus_neurons', id=1) - CircuitNodeId(population='thalamus_neurons', id=27204)\n",
      "Edge count: 4\n"
     ]
    }
   ],
   "source": [
    "for _source_id, _target_id, _edge_count in edge_population.iter_connections(source_ids, target_ids, return_edge_count=True):\n",
    "    print(_source_id, '-', _target_id)\n",
    "    print(f'Edge count: {_edge_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomizing the output order\n",
    "\n",
    "We can use `shuffle=True` To randomize the order of the results. \n",
    "\n",
    "So let's see the non-randomized order of the connections between the first 10 nodes. For easier reading, let's only print the numeric part of the `CircuitNodeIds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: source:  2 --- target:  0\n",
      " 2: source:  0 --- target:  4\n",
      " 3: source:  5 --- target:  4\n",
      " 4: source:  1 --- target:  5\n"
     ]
    }
   ],
   "source": [
    "it = enumerate(edge_population.iter_connections(range(10), range(10)))\n",
    "for i, (_source_id, _target_id) in it:\n",
    "    print(f'{i+1:2d}: source: {_source_id.id:2d} --- target: {_target_id.id:2d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now by setting the `shuffle` flag in the call, we'll get the above source-target pairs in a different order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: source:  5 --- target:  4\n",
      " 2: source:  0 --- target:  4\n",
      " 3: source:  1 --- target:  5\n",
      " 4: source:  2 --- target:  0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) # Just to keep the results consistent in the notebook\n",
    "\n",
    "it = enumerate(edge_population.iter_connections(range(10), range(10), shuffle=True))\n",
    "for i, (_source_id, _target_id) in it:\n",
    "    print(f'{i+1:2d}: source: {_source_id.id:2d} --- target: {_target_id.id:2d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using each node only once (at max.) as a source and as a target\n",
    "\n",
    "Let's look at the connections between first 15 node ids. For easier reading, again, let's only print the numeric part of the `CircuitNodeId`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 : source:  2 --- target:  0\n",
      "W2 : source: 10 --- target:  0\n",
      "W3 : source: 14 --- target:  0\n",
      "W4 : source:  0 --- target:  4\n",
      "W5 : source:  5 --- target:  4\n",
      "W6 : source:  1 --- target:  5\n",
      "W7 : source: 13 --- target:  5\n",
      "W8 : source: 11 --- target:  6\n",
      "W9 : source:  8 --- target: 10\n",
      "W10: source:  2 --- target: 14\n",
      "W11: source: 13 --- target: 14\n"
     ]
    }
   ],
   "source": [
    "it = enumerate(edge_population.iter_connections(range(15), range(15)))\n",
    "for i, (_source_id, _target_id) in it:\n",
    "    print(f'{\"W\"+str(i+1):3s}: source: {_source_id.id:2d} --- target: {_target_id.id:2d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 11 different source-target pairs. Note that the indices are prefixed with `W` (stands for Without a flag) to distinct them from the following. Let's see what happens when we set `unique_node_ids=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U1 : source:  2 --- target:  0\n",
      "U2 : source:  0 --- target:  4\n",
      "U3 : source:  1 --- target:  5\n",
      "U4 : source: 11 --- target:  6\n",
      "U5 : source:  8 --- target: 10\n",
      "U6 : source: 13 --- target: 14\n"
     ]
    }
   ],
   "source": [
    "it = enumerate(edge_population.iter_connections(range(15), range(15), unique_node_ids=True))\n",
    "for i, (_source_id, _target_id) in it:\n",
    "    print(f'{\"U\"+str(i+1):3s}: source: {_source_id.id:2d} --- target: {_target_id.id:2d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we've effectively lost 5 pairs of source-target pairs somewhere. \n",
    "\n",
    "So what happened here? The indices were prefixed with `U` (unique nodes only) to distinct them from the previous output. Let's go through the output and indices `W1`-`W11` of the previous example without `unique_node_ids` flag set and compare it to the output above:\n",
    "* `W1`: kept (`U1`)\n",
    "* `W2`,`W3`: removed (id `0` used as a **target** in `W1`)\n",
    "* `W4`: kept (`U2`)\n",
    "* `W5`: removed (id `4` used as a **target** in `W4`)\n",
    "* `W6`: kept (`U3`)\n",
    "* `W7`: removed (id `5` used as a **target** in `W6`)\n",
    "* `W8`: kept (`U4`)\n",
    "* `W9`: kept (`U5`)\n",
    "* `W10`: removed (id `2` used as a **source** in `W1`)\n",
    "* `W11`: kept (`U6`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _\"Please tell me the above also works with queries\"_\n",
    "What kind of a software you think we're running here, pal? \n",
    "\n",
    "Obviously, `iter_connections` can also be called with any of the accepted node queries. The ids will be resolved on the fly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1: source: 33550 --- target: 28603\n",
      " 2: source: 33743 --- target: 28603\n",
      " 3: source: 33794 --- target: 28603\n",
      " 4: source: 33818 --- target: 28603\n",
      " 5: source: 34043 --- target: 28603\n",
      " 6: source: 34773 --- target: 28603\n",
      " 7: source: 34942 --- target: 28603\n",
      " 8: source: 35126 --- target: 28603\n",
      " 9: source: 35169 --- target: 28603\n",
      "10: source: 35579 --- target: 28603\n",
      "11: ...\n"
     ]
    }
   ],
   "source": [
    "it = edge_population.iter_connections(\n",
    "    'mc2;VPL',            # node set\n",
    "    {'region': 'mc2;Rt'}, # dict query\n",
    ")\n",
    "for i, (_source_id, _target_id) in enumerate(it):\n",
    "    if i == 10: # Let's only print first 10\n",
    "        print(f'{i+1:2d}: ...')\n",
    "        break\n",
    "    print(f'{i+1:2d}: source: {_source_id.id:2d} --- target: {_target_id.id:2d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance optimizations\n",
    "\n",
    "Now that we understand how `iter_connections` works, what can we do with it? What is the magic therein? \n",
    "\n",
    "Well, it's not really about _what_ it can do but _how_ it does it. As mentioned before, the whole purpose of using the iterators is to be memory efficient. Where it especially shines are the cases in which you are handling large number of nodes/edges and aren't necessarily interested in all of the data collected in the process.\n",
    "\n",
    "Let's take a look at an example.\n",
    "\n",
    "### CASE: Synapses between node sets\n",
    "\n",
    "To demonstrate the magick of `iter_connections`, let's have a simple, straightforward example. We want to count the number of synapses between two node sets.\n",
    "\n",
    "Now, we're not interested in the individual edge ids, just the number of synapses between two node sets. Perhaps we'd also like some statistics on how many of them are there on average between each of the source-target node pair, what is the deviation, etc.\n",
    "\n",
    "Let's first define a source and a target node set and a helper function for printing the stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source nodes: 4909\n",
      "Number of target nodes: 8999\n"
     ]
    }
   ],
   "source": [
    "source_node_set = 'mc2;Rt'\n",
    "target_node_set = 'mc2;VPL'\n",
    "\n",
    "def print_statistics(pair_syns):\n",
    "    print(f\"There is a total of {np.sum(pair_syns)} synapses from '{source_node_set}' to '{target_node_set}'\")\n",
    "    print(\"\\nSynapses between source-target node pairs:\")\n",
    "    print(f\"- avg: {np.mean(pair_syns):.2f}\")\n",
    "    print(f\"- std: {np.std(pair_syns):.2f}\")\n",
    "    print(f\"- min: {np.min(pair_syns)}\")\n",
    "    print(f\"- max: {np.max(pair_syns)}\")\n",
    "\n",
    "print(f'Number of source nodes: {len(edge_population.source.ids(source_node_set))}')\n",
    "print(f'Number of target nodes: {len(edge_population.target.ids(target_node_set))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now let's get the synapses and print the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 3245906 synapses from 'mc2;Rt' to 'mc2;VPL'\n",
      "\n",
      "Synapses between source-target node pairs:\n",
      "- avg: 4.86\n",
      "- std: 4.23\n",
      "- min: 1\n",
      "- max: 95\n",
      "\n",
      "Runtime: 12.89 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "it = edge_population.iter_connections(source_node_set, target_node_set, return_edge_count=True)\n",
    "pairwise_syns = np.fromiter((count for _,__,count in it), dtype=int)\n",
    "print_statistics(pairwise_syns)\n",
    "\n",
    "print(f'\\nRuntime: {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we'd achieve the same with the a bit more memory-heavy approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 3245906 synapses from 'mc2;Rt' to 'mc2;VPL'\n",
      "\n",
      "Synapses between source-target node pairs:\n",
      "- avg: 4.86\n",
      "- std: 4.23\n",
      "- min: 1\n",
      "- max: 95\n",
      "\n",
      "Runtime: 5.23 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "result = edge_population.pathway_edges(source_node_set,target_node_set, properties=['@source_node', '@target_node'])\n",
    "print_statistics(result.value_counts().values)\n",
    "print(f'\\nRuntime: {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _\"Dude, you just told me that `iter_connections` is supposed to be awesome, why is it slower?\"_\n",
    "\n",
    "Well spotted. There are cases, in which `iter_connections` is actually outperformed (runtime-wise) by the memory-heavy options. Worry not, we're merely warming up here. Let's shift gears and introduce a significantly bigger target node set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source nodes: 4909\n",
      "Number of target nodes: 64856\n"
     ]
    }
   ],
   "source": [
    "target_node_set = 'VPL_TC'\n",
    "print(f'Number of source nodes: {len(edge_population.source.ids(source_node_set))}')\n",
    "print(f'Number of target nodes: {len(edge_population.target.ids(target_node_set))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bumped up the number of target nodes by roughly one order of magnitude. The source nodes were left intact. Now, let's see what happens to the runtimes. Let's first run the `iter_connections` version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 4706551 synapses from 'mc2;Rt' to 'VPL_TC'\n",
      "\n",
      "Synapses between source-target node pairs:\n",
      "- avg: 4.63\n",
      "- std: 3.96\n",
      "- min: 1\n",
      "- max: 95\n",
      "\n",
      "Runtime: 102.22 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "it = edge_population.iter_connections(source_node_set, target_node_set, return_edge_count=True)\n",
    "pairwise_syns = np.fromiter((count for _,__,count in it), dtype=int)\n",
    "print_statistics(pairwise_syns)\n",
    "print(f'\\nRuntime: {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took quite some time. Let's see how the previously faster, `pathway_edges` implementation performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 4706551 synapses from 'mc2;Rt' to 'VPL_TC'\n",
      "\n",
      "Synapses between source-target node pairs:\n",
      "- avg: 4.63\n",
      "- std: 3.96\n",
      "- min: 1\n",
      "- max: 95\n",
      "\n",
      "Runtime: 130.58 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "result = edge_population.pathway_edges(source_node_set,target_node_set, properties=['@source_node', '@target_node'])\n",
    "print_statistics(result.value_counts().values)\n",
    "print(f'\\nRuntime: {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a significant drop in performance in comparison to `iter_connections`, even though the number of edges/synapses wasn't _that_ much higher. Why the difference?\n",
    "\n",
    "By not going into too much of technicalities, it boils down to:\n",
    "* `pathway_synapses` needs to handle all the data at once\n",
    "   * it needs to get all connecting edges and their source and target nodes\n",
    "   * from the huge dataframe, it needs to find unique source-target pairs and count how many times they appear\n",
    "      * `pandas.value_counts()` leads to creating another dataframe which consumes even more memory  \n",
    "   * everything is kept in memory throughout the process\n",
    "* `iter_connections` only needs to handle one source-target pair at a time\n",
    "   * after required data from one iteration is collected, rest of the data can be discarded from memory\n",
    "\n",
    "You might wonder what would happen if we bumped up the number of source nodes. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of source nodes: 35567\n",
      "Number of target nodes: 64856\n"
     ]
    }
   ],
   "source": [
    "source_node_set = 'Rt_RC'\n",
    "print(f'Number of source nodes: {len(edge_population.source.ids(source_node_set))}')\n",
    "print(f'Number of target nodes: {len(edge_population.target.ids(target_node_set))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by using `'Rt_RC'`, we roughly bumped up the number of source sodes by one order of magnitude. \n",
    "\n",
    "Let's see what happens when we run it with `iter_connections`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 29455533 synapses from 'Rt_RC' to 'VPL_TC'\n",
      "\n",
      "Synapses between source-target node pairs:\n",
      "- avg: 4.70\n",
      "- std: 4.04\n",
      "- min: 1\n",
      "- max: 102\n",
      "\n",
      "Runtime: 100.89 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "it = edge_population.iter_connections(source_node_set, target_node_set, return_edge_count=True)\n",
    "pairwise_syns = np.fromiter((count for _,__,count in it), dtype=int)\n",
    "print_statistics(pairwise_syns)\n",
    "print(f'\\nRuntime: {time()-t0:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, `iter_connections` was still faster than the `pathway_synapses` method was with the smaller source node set. \n",
    "\n",
    "Surely, the `pathway_synapses` can't be that much worse, right?  Boy, can it ever. Running the same with the `pathway_synapses` method took **over 30 minutes**. \n",
    "\n",
    "Obviously, we didn't include it in the notebook, but if you **truly** want to try it out yourself, feel free to do so. You have been warned.\n",
    "\n",
    "### Lesson's learned\n",
    "* If you know you'll be working with big sample sizes and big datasets, use `iter_connections`\n",
    "  * if you are unsure, you can still use it, it's not _that_ much slower \n",
    "* If your code hangs seemingly forever on\n",
    "  * a call to `pathway_synapses`/`pair_edges`/`afferent_edges`/`efferent_edges`, you might want to try if `iter_connections` solves your issue\n",
    "  * a `pandas.DataFrame` operation, see if you can achieve the same with `iter_connections`. It might just save your day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Conclusion\n",
    "In this notebook, we learned how to and why use the iterative approach (`iter_connections`) when working with bigger datasets to avoid having our code hanging / nodes running out of memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
